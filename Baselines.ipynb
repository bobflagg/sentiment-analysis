{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Baselines for Sentiment Analysis\n",
    "\n",
    "A good starting point for understanding recent work in sentiment analysis and text classification is \n",
    "[_Baselines and Bigrams: Simple, Good Sentiment and Topic Classification_](http://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf) by Sida Wang and Christopher D. Manning. In this notebook, I'll implement the models described in that paper and try to reproduce their results on several datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| AthR  | XGraph | BbCrypt|   CR   |  IMDB  | MPQA   | RT-2k  | RTs    | subj   |              |\n",
    "|-------|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|-------------:|\n",
    "| 85.13 |  91.19 |  99.40 |  79.97 |  86.59 |  86.27 |  85.85 |  79.03 |  93.56 |  MNB-bigram  |\n",
    "| 84.99 |  89.96 |  99.29 |  79.76 |  83.55 |  85.29 |  83.45 |  77.94 |  92.58 |  MNB-unigram | \n",
    "| 83.73 |  86.17 |  97.68 |  80.85 |  89.16 |  86.72 |  87.40 |  77.72 |  91.74 |  SVM-bigram  | \n",
    "| 82.61 |  85.14 |  98.29 |  79.02 |  86.95 |  86.15 |  86.25 |  76.23 |  90.84 |  SVM-unigram |  \n",
    "| 87.66 |  90.68 |  99.50 |  81.75 |  91.22 |  86.32 |  89.45 |  79.38 |  93.18 |  NBSVM-bigram|  \n",
    "| 87.94 |  91.19 |  99.70 |  80.45 |  88.29 |  85.25 |  87.80 |  78.05 |  92.40 |  SVM-unigram |\n",
    "\n",
    "[peng](http://nlp.stanford.edu/wiki/Software/Classifier/Sentiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Datasets\n",
    "\n",
    "The baselines and bigrams paper uses several datasets to run sentiment analysis experiments. \n",
    "In this section I'll show how to prepare these datasets for training and evaluating classifiers.\n",
    "\n",
    "### RT-s\n",
    "\n",
    "The dataset consists of 2,000 full-length movie reviews and was introducted in \n",
    "[Pang and Lee, 2004](http://www.aclweb.org/anthology/P04-1035).\n",
    "\n",
    "### RT-2k\n",
    "\n",
    "The dataset consists of 2,000 full-length movie reviews and was introducted in \n",
    "[Pang and Lee, 2004](http://www.aclweb.org/anthology/P04-1035).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes (MNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBSVM\n",
    "\n",
    "There are several implementations of NBSVM available; for example:\n",
    "\n",
    "* Sida Wang's original [implementation](https://github.com/sidaw/nbsvm) in Matlab.  \n",
    "* A Python [version](https://github.com/mesnilgr/nbsvm) by Gr√©goire Mesnil.  \n",
    "* Daniel Pressel's [version](https://github.com/dpressel/nbsvm-xl) in Java.  \n",
    "\n",
    "I'll follow the beautiful [implementation](https://github.com/Joshua-Chin/nbsvm) in scikit-learn by Joshua Chin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import spmatrix, coo_matrix\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model.base import LinearClassifierMixin, SparseCoefMixin\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "class NBSVM(BaseEstimator, LinearClassifierMixin, SparseCoefMixin):\n",
    "\n",
    "    def __init__(self, alpha=1, C=1, beta=0.25, fit_intercept=False):\n",
    "        self.alpha = alpha\n",
    "        self.C = C\n",
    "        self.beta = beta\n",
    "        self.fit_intercept = fit_intercept\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        if len(self.classes_) == 2:\n",
    "            coef_, intercept_ = self._fit_binary(X, y)\n",
    "            self.coef_ = coef_\n",
    "            self.intercept_ = intercept_\n",
    "        else:\n",
    "            coef_, intercept_ = zip(*[\n",
    "                self._fit_binary(X, y == class_)\n",
    "                for class_ in self.classes_\n",
    "            ])\n",
    "            self.coef_ = np.concatenate(coef_)\n",
    "            self.intercept_ = np.array(intercept_).flatten()\n",
    "        return self\n",
    "\n",
    "    def _fit_binary(self, X, y):\n",
    "        p = np.asarray(self.alpha + X[y == 1].sum(axis=0)).flatten()\n",
    "        q = np.asarray(self.alpha + X[y == 0].sum(axis=0)).flatten()\n",
    "        r = np.log(p/np.abs(p).sum()) - np.log(q/np.abs(q).sum())\n",
    "        b = np.log((y == 1).sum()) - np.log((y == 0).sum())\n",
    "\n",
    "        if isinstance(X, spmatrix):\n",
    "            indices = np.arange(len(r))\n",
    "            r_sparse = coo_matrix(\n",
    "                (r, (indices, indices)),\n",
    "                shape=(len(r), len(r))\n",
    "            )\n",
    "            X_scaled = X * r_sparse\n",
    "        else:\n",
    "            X_scaled = X * r\n",
    "\n",
    "        lsvc = LinearSVC(\n",
    "            C=self.C,\n",
    "            fit_intercept=self.fit_intercept,\n",
    "            max_iter=10000\n",
    "        ).fit(X_scaled, y)\n",
    "\n",
    "        mean_mag =  np.abs(lsvc.coef_).mean()\n",
    "        coef_ = (1 - self.beta) * mean_mag * r + self.beta * (r * lsvc.coef_)\n",
    "        intercept_ = (1 - self.beta) * mean_mag * b + self.beta * lsvc.intercept_\n",
    "\n",
    "        return coef_, intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def load_imdb(data_directory='/home/data/sentiment-analysis-and-text-classification/aclImdb'):\n",
    "    print(\"Vectorizing Training Text\")\n",
    "    \n",
    "    train_pos = glob.glob(os.path.join(data_directory, 'train', 'pos', '*.txt'))\n",
    "    train_neg = glob.glob(os.path.join(data_directory, 'train', 'neg', '*.txt'))\n",
    "\n",
    "    token_pattern = r'\\w+|[%s]' % string.punctuation\n",
    "\n",
    "    vectorizer = CountVectorizer(\n",
    "        'filename', \n",
    "        ngram_range=(1, 3),\n",
    "        token_pattern=token_pattern,\n",
    "        binary=True\n",
    "    )\n",
    "    X_train = vectorizer.fit_transform(train_pos+train_neg)\n",
    "    y_train = np.array([1]*len(train_pos)+[0]*len(train_neg))\n",
    "\n",
    "    print(\"Vocabulary Size: %s\" % len(vectorizer.vocabulary_))\n",
    "    print(\"Vectorizing Testing Text\")\n",
    "\n",
    "    test_pos = glob.glob(os.path.join(data_directory, 'test', 'pos', '*.txt'))\n",
    "    test_neg = glob.glob(os.path.join(data_directory, 'test', 'neg', '*.txt'))\n",
    "\n",
    "    X_test = vectorizer.transform(test_pos + test_neg)\n",
    "    y_test = np.array([1]*len(test_pos)+[0]*len(test_neg))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing Training Text\n",
      "Vocabulary Size: 4996192\n",
      "Vectorizing Testing Text\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load_imdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NBSVM(C=1, alpha=1, beta=0.25, fit_intercept=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbsvm = NBSVM()\n",
    "mnbsvm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.92032\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy: %s' % mnbsvm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
